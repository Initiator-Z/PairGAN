{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "from numpy import expand_dims, zeros, ones, vstack, asarray, savez_compressed, load \n",
    "from numpy.random import randn, randint\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape=(256,256,3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(4, 4, padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(8, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(16, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(32, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(64, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(256, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(512, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 256 * 8 * 8\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((8, 8, 256)))\n",
    "    model.add(Conv2DTranspose(512, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(256, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(128, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(64, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(32, 4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(3, (3,3), activation='sigmoid', padding='same'))\n",
    "    return model\n",
    "\n",
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = dict()\n",
    "path = 'data/tm0050/'\n",
    "size = (256,256)\n",
    "\n",
    "for i in range(231):\n",
    "    pixel1 = img_to_array(load_img(path+str(i)+'.jpg', target_size=size))\n",
    "    pixel2 = img_to_array(load_img(path+str(i+1)+'.jpg', target_size=size))\n",
    "    image_dict[i] = pixel1, pixel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original scans based on the imposed scan(key in dict)\n",
    "def load_real_samples(key):\n",
    "    X1 = image_dict[key][0] / 255.0\n",
    "    X1 = np.expand_dims(X1, axis=0)\n",
    "    X2 = image_dict[key][1] / 255.0\n",
    "    X2 = np.expand_dims(X2, axis=0)\n",
    "    X = vstack((X1, X2))\n",
    "    y = ones((2,1))\n",
    "    return X, y\n",
    "\n",
    "# Run an image through MLP to get latent representation.\n",
    "def generate_latent_representation(latent_dim, image_shape=(256,256,3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, 3, padding='same', input_shape=image_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, 3, strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(256, 3, strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(latent_dim))\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# Generate two fake samples\n",
    "def generate_fake_samples(image, g_model, MLP): \n",
    "    X = image / 255.0\n",
    "    X = expand_dims(X, 0)\n",
    "    X = MLP.predict(X)\n",
    "    X = g_model.predict(X)\n",
    "    y = zeros(1) \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(X1, X2, epoch):\n",
    "    # plot images\n",
    "    for i in range(2 * 2):\n",
    "        # define subplot\n",
    "        pyplot.subplot(2, 2, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(X1[i, :, :, 0], cmap='gray_r')\n",
    "        pyplot.imshow(X2[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot_e%03d.jpg' % (epoch+1)\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()\n",
    "\n",
    "def train(MLP, g1_model, g2_model, d_model, gan1_model, gan2_model, path, size=256, n_epochs=100):\n",
    "    for i in range(n_epochs):\n",
    "        for filename in listdir(path):\n",
    "            j = filename.find(\".\")\n",
    "            name = filename[:j]\n",
    "            image = load_img(path+filename, target_size=(size,size))\n",
    "            image = img_to_array(image)\n",
    "            \n",
    "            X_real, y_real = load_real_samples(int(name))\n",
    "            X1_fake, y1_fake = generate_fake_samples(image, g1_model, MLP)\n",
    "            X2_fake, y2_fake = generate_fake_samples(image, g2_model, MLP)\n",
    "            X_fake, y_fake = vstack((X1_fake, X2_fake)), vstack((y1_fake, y2_fake))\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)  \n",
    "            \n",
    "            X_gan = image / 255.0\n",
    "            X_gan = expand_dims(X_gan, 0)\n",
    "            X_gan = MLP.predict(X_gan)\n",
    "            y_gan = ones((4,1))\n",
    "            g_loss1 = gan1_model.train_on_batch(X_gan, y_gan)\n",
    "            g_loss2 = gan2_model.train_on_batch(X_gan, y_gan)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('>%d, d=%.3f, d=%.3f, g=%.3f' % (i+1, d_loss, g_loss1, g_loss2))\n",
    "            save_plot(X1_fake, X2_fake, i)\n",
    "        if (i+1) % 500 == 0:\n",
    "            fname1 = 'generator_model_%03d.h5' % (i + 1)\n",
    "            fname2 = 'generator_model_%03d.h5' % (i + 1)\n",
    "            g1_model.save(fname1)\n",
    "            g2_model.save(fname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "g1_model = define_generator(latent_dim)\n",
    "g2_model = define_generator(latent_dim)\n",
    "d_model = define_discriminator()\n",
    "gan1_model = define_gan(g1_model, d_model)\n",
    "gan2_model = define_gan(g2_model, d_model)\n",
    "path = 'data/impo0050/'\n",
    "MLP = generate_latent_representation(latent_dim)\n",
    "\n",
    "train(MLP, g1_model, g2_model, d_model, gan1_model, gan2_model, path, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
